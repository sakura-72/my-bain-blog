---
title: "9 Suchmaschinen und Discovery-Systeme 2/2"
date: 2020-12-11
---

## Nachtrag LIDO
Die Dozenten machten als Erstes ein kleines Nachtrag zu LIDO, da anscheineind ein Angstgefühl in der letzen Lektion verbreitet wurde. Einiges habe ich schon in [meinem Blog](https://sakura-72.github.io/my-bain-blog/2020/11/27/tag8.html) über LIDO geschrieben gehabt. Deswegen werde ich hier nicht vertieft darauf eingehen, sondern nur Ergänzungen zu den Punkten, die ich eventuell nicht beschrieben hatte, geben.
LIDO ist leztendlich einfach ein XML-Format, mit welchem man mit den gleichen Tools und Methoden wie bei anderen Formate verwenden kann. Das Format ist nicht unbedingt komplizierter, sondern ist einfach anders als andere Formate aufgebaut. Hingegen ist CIDO CRM wirklich kompliziert. 
Im blog erwähnte ich den Vorteil von Linked Data-Strutkuren, hinzu kommen noch die Verwendung von kontrollierten Ontologien/Vokabularen und die Wiederverwendung von Entitäten wie Ereignissen.

Als Antwort einer Anmerkung aus [Gaby's Blogeintrag der letzten Sitzung](https://regrebneuel.github.io/bain-log/2020-11-27/OpenRefine-reloaded) gehen die Dozente noch auf einer Recherche zur Transformation von LIDO in andere Formate mit Crosswalks ein. Vielleicht ist es mir auch irgendwann hilfreich, also möchte ich [hier](https://bain.felixlohmeier.de/#/05_metadaten-modellieren-und-schnittstellen-nutzen?id=metadatenstandard-lido) zu diesen Referenzen verlinken.

# Suchmaschinen und Discovery-Systeme 2/2

## Solr
Suchmaschine Solr als Basis für das Discoverysystem VuFind ist zusammen mit Elasticsearch den Industriestandard. Die beide Suchmaschine sind eben die am meistbenutzenden Suchmaschine für Webseiten und wo Volltextsuche gebraucht werden. Im Normalfall wird vor einem Import in einem Schema festgelegt, welche Felder es gibt und welchen Datentypen diese beinhalten dürfen. Letzeres ist wichtig, damit Geokoordinaten oder einem Datum durchsuchbar sind. So kann man nach Räume oder Zeiträume suchen und nicht nur nach Textfelder. Allerdings kann man theoretisch auch Daten ohne Schema – als «Schemaless» – in Solr importieren und man hat eine Volltextsuche, aber dies ohne Kontrolle.
Solar ist ohne Suchoberfläche per se gegeben: es gibt zwar eine, die intergriert ist, aber nur für Demo-Zwecken gedacht. Also nur zum Testen ob das System funktionniert. Man braucht also eine eigene Webseite und eigene Tools, um Solr für die Nutzung zu integrieren.
Dazu basiert das Discoverysystem VuFind auf Solr, sowie auch viele Andere wie z.B. Ex Libris Primo.

## Unterschied zwischen Suchindex (Solr) und Datenbank (MySQL)
Die Unterschiede sind doch grösser als man meinen könnte, obwohl in beide Systeme Daten importiert werden und aufgerufen werden. 
* Die Datenstrutkur ist ein wesentlichen Unterschied zwischen Suchindex und Datenbank. Bei einem Suchindex handelt es sich um eine flache Dokumentstruktur, das heisst jedes Dokument steht für sich allein ohne Verbindung zu Anderen. Hingegen hat man bei einer Datenbank relationale Datensätze, so können Daten auf einander verweisen. 
* Auch gibt es Unterschiede bei der Suchanfrage. Bei einer Datenbank gibt es nur einen reinen Glyphenvergleich, welches mit Operatoren (AND, OR, etc.) unterstützt werden kann, so wird die Angabe zu den Daten 1:1 verglichen und den zutreffenden Ergebnis herausgegeben. Bei einem Suchindex wie Solr wird eine lexikalische Suche durchgeführt, das heisst das eine Angabe wird als Begriff mit einer Grammatik verstanden und so erhält man sinngemässe Treffer (nicht nur 1:1 Resultate). 
* Dafür geben Datenbanken den Vorteil, dass Daten nach Ihre Konsistenz überprüft werden. Dies ist nicht der Fall bei einem Suchindex, was bedeutet, dass wenn ein Fehler beim Indexieren aufretten sollte und den Server z.B. abbricht, muss der Suchindex neu aufgebaut werden. Somit ist ein Suchindex eine Art flüchtiger Speicher, wo Daten nicht auf die Dauer wie bei einer Datenbank sicher gespeichert werden können.
* In einem Suchindex sind die Daten statisch und können somit nicht verändert oder aktualisiert werden. Einzig was möglich ist, ist eine Kopie eines Datensatz zu haben, dieser nach Bearbeitung im System zu laden und den «alten» Datensatz als gelöscht zu markieren, damit dieser nicht in Suchergenisse vorkommt. Die Aktualisierzung von Daten ist in Datenbanken möglich und so spart man sich immer Kopien machen zu müssen.

Schlussendlich diese Unterschiede zwischen Suchindex wie Solr und Datenbanken wie MySQl deffinieren auch ganz einfach ihre Einsatzwecke. Wo Ziel eines Suchindexes den Retrieval (bzw. die Suche) ist, ist das Ziel einer Datenbank die Speicherung (Storage). Die Storage-Funktion von Datenbanken wird auch CRUD gennant, was für ***C**reate **R**ead **U**pdate **D**elete* steht.

## Sichtung von Solr in VuFind
Nun schauen wir uns Solr in der Praxis ein, dabei ist zu achten, dass diese Links nur in der virtuellen Maschine funktionnieren
* Administrationsoberfläche: <http://localhost:8983>
* Bibliografische Daten im Index "biblio": <http://localhost:8983/solr/#/biblio>
* Technische Suchoberfläche in Solr für Index "biblio": <http://localhost:8983/solr/#/biblio/query>
* Schema des Index "biblio": <http://localhost:8983/solr/#/biblio/schema>
   * Erläuterung der VuFind-Felder in VuFind Doku: <https://vufind.org/wiki/development:architecture:solr_index_schema>
![Query in Solr](https://sakura-72.github.io/my-bain-blog/images/query_solr.png)
![Schema in Solr](https://sakura-72.github.io/my-bain-blog/images/schema_solr.png)

### Literatur zu Solr

* Das offizielle Handbuch zu Solr beinhaltet ein gutes Tutorial (ca. 2 Stunden): <https://lucene.apache.org/solr/guide/8_7/solr-tutorial.html>

>Hinweis hier, wenn man mehr über Solr wissen möchte.

## Übung zur Datenintegration

Ziel: Import der mit MarcEdit und OpenRefine konvertierten Daten aus Koha, ArchivesSpace, DSpace und DOAJ in VuFind


### Testdaten löschen
>!Damit man frisch starten kann :)

Quelle: https://vufind.org/wiki/indexing:re-indexing

```
/usr/local/vufind/solr.sh stop
rm -rf $VUFIND_HOME/solr/vufind/biblio/index $VUFIND_HOME/solr/vufind/biblio/spell*
/usr/local/vufind/solr.sh start
```

Übung zur Datenintegration

>Problem: Solr erwartet eine ID, welche bei MARC den Feld 001 entsprechen würde. Schwierigkeit ist dabei, dass dieses Feld in Marc nicht obligatorisch ist. 
Dieses Feld ist bei den Dateien von Dspace nicht verfügbar, so müsste man selbst dieses Feld ertstellen. 
Wichtig aber, dass die IDs eindeutig sind, ansonsten löschen wir ein schon hochgeladenes Datensatz.


Gruppendiskussion: Perfekter Katalog
>Was wäre mein Wunsch?

