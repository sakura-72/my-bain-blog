---
title: "7 Metadaten modellieren und Schnittstellen nutzen 2/2"
date: 2020-11-20
---
# Zwischenstand – neues Schaubild
![neues Schaubild](https://sakura-72.github.io/my-bain-blog/images/schaubild_openrefine.png)

Das Schaubild wurde für diese Lektion nochmals angepasst und dies indem es mit OpenRefine angereichert wurde. Für diese Lektion mussten wird schon OpenRefine installiert haben, sowie die [Lehrmaterialien von Library Carpentry zu OpenRefine](https://librarycarpentry.org/lc-open-refine/) durchgehen. Die Software lass sich ohne Probleme installieren und die Lehrmaterialien waren sehr gut beschrieben, so dass ich da auch keine Schwierigkeiten hatte.

Nun haben wir während dieser 7. Lektion mehr über OpenRefine gelernt, weitere Übungen durchgeführt und einen Einblick über Weitere Tools zur Metadatentransformation
sowie über die Nutzung von JSON-APIs erhalten.

# OpenRefine
Den Claim von OpenRefine finde ich schon mal sehr nett:
> «A free, open source, powerful tool for working with messy data».

Die Software besitzt eine graphische Oberfläche ähnlich wie eine klassische Tabellenverarbeitungsanwendung, welche der Analyse, Bereininung, Konvertierung und Anreicherung von Daten dient. Zum Beispiel kann man damit unterschiedliche Zahlenformate, Schreibweise oder Abkürzugen vereinheitlichem, sowie auch Datensätze mit Informationen aus anderen Quellen (GND z.B.) anreichern ([Alex's blog](https://alexmuster.github.io/lerntageblog/2020/11/20/tag7.html)). Im Normalfall wird OpenRefine lokal installiert und über einen Browser verwendet. Es ist möglich es auf einem Server zu installieren, damit mehere darauf Zugriff haben, allerdings besitzt die Software keinerlei Nutzerverwaltung und somit müssen sich die Benutzende bei einer solchen Nutzung gut absprechen.

OpenRefine ist keine spezifische Archiv- oder Bibliothekanwendung, sondern wird von unterschiedlichen Anwender'innen (Bibliothekar'innen, Semantic Web, Forschungszwecke, Datenjournalist'innen) verwendet und dies auch für unterschiedliche Aufgaben. Spannend fand ich, dass Ex Libris das Tool bzw. die Funktionalitäten auch übernommen hat und es ALMA Refinde nennt. Wenn es um die Aufgaben geht, sehen wir hier die Resultate von drei Umfragen, welche von OpenRefine durchgeführt worden sind und nach dem Einsatz des Programms seien Nutzer befragte:

![Einsatzbereiche von OpenRefine](https://sakura-72.github.io/my-bain-blog/images/tasks_openrefine.png)

So wie man es sehen kann wird die Anwendung vor hauptsächlich bentuzt für was Sie auch entwickelt worden ist: die Bereiningung und die Konvertierung.

Zum Thema Formate in OpenRefine, kann man dies betrachten:
* Die Software ist besonders für tabellarische Daten (CSV, TSV, XLS, XLSX und auch TXT) geeignet.
* Einfaches "flaches" XML (z.B. MARCXML) oder JSON ist möglich zu modellieren.
* Komplexes XML mit Hierarchien (z.B. EAD) ist möglich, aber nur mit Zusatztools. Mit verschachteten Strukturen wird es deutlich schwiriger, da solche komplexe Strukturen sich nicht sehr gut in Tabellen abilden lassen.
* Kann auch in Kombination mit MarcEdit für Analyse und Transformation von MARC21 benutzt werden.

Interessant fand ich die [Statistiken von OpenRefine](https://github.com/OpenRefine/OpenRefine/graphs/contributors) auf GitHub zu sehen. Die Software heisste vorher Google Refine, bzw. zuvor noch Freebase Gridworks, und wurde 2010 von Google gekaft sowie intensiv 2010/2011 entwickelt bis sie dann als Open Source freigegeben worden ist. Einige haben die Software dann unter dem Namen OpenRefine weiterentwickelt, aber es brauchte ein paar Jahre bis die Contributors intenstiv daran arbeiteten. Erst ab 2017 kann man eine Intensivität der Entwicklungen merken, dies (siehe Bild). Die Entwicklung wird hin und wieder finanziell gefördert, um Openrefine zu verbessern.

![Statistik von OpenRefine](https://sakura-72.github.io/my-bain-blog/images/statistik_openrefine.png)

## Übung CSV nach MARCXML
Hauptbestandteil dieser Lektion war die Funktion Templating Exporter zu verwenden, um einem CSV in einem MARCXML zu konvertieren. Die Funktion findet man im Menü unter Export > Templating. Dafür verwendeten wird die [Liste der MARC21 Felder der Library of Congress](https://www.loc.gov/marc/bibliographic/). 
Auch konnte man sich mit diesem [Beispiel](https://www.loc.gov/standards/marcxml/xml/collection.xml) auch wieder von der Library of Congress behelfen. Pfiou! Zum Glück sind mir die Felder nicht komplett Fremd, da ich einige im Modul STAN durch die formale Erschliessung in Aleph kennengelernt habe.

Bei diesem Vorgehen wird eine von OpenRefine eigene Template-Sprache benutzt: **GREL**. Im Gegensatzt zu der Konvertierung mit MarcEdit ist bei OpenRefin den Template komplett bearbeitbar. Mehr oder weniger Felder können benutzt werden. Man hat somit die Vorteile der komplette Freiheit, gleichzeitig muss man aber alles manuell und intellectuell eingeben, was man benutzten möchte. Eine Basis-Vorlage dafür gaben uns schon die Dozenten. 

* **Prefix**:
    ```xml
    <collection xmlns="http://www.loc.gov/MARC21/slim">
    ```
* **Row Separator**: (Zeilenumbruch)
* **Suffix**:
    ```xml
    </collection>
    ```
    
* **Row Template**:

```xml
<record>
<leader>     nab a22     uu 4500</leader>
<controlfield tag="001">{{cells['URL'].value.replace('https://doaj.org/article/','').escape('xml')}}</controlfield>
<datafield tag="022" ind1=" " ind2=" ">
    <subfield code="a">{{cells['ISSNs'].value.escape('xml')}}</subfield>
</datafield>
<datafield tag="100" ind1="0" ind2=" ">
    <subfield code="a">{{cells['Authors'].value.split('|')[0].escape('xml')}}</subfield>
</datafield>
<datafield tag="245" ind1="0" ind2="0">
    <subfield code="a">{{cells["Title"].value.escape('xml')}}</subfield>
</datafield>{{
forEach(cells['Authors'].value.split('|').slice(1), v ,'
<datafield tag="700" ind1="0" ind2=" ">
    <subfield code="a">' + v.escape('xml') + '</subfield>
</datafield>')
}}
</record>
```

> Row Template: hier noch einen kleinen Hinweis. Was wir hier drin schreiben, wird für jeden Datensatz einmal ausgegeben.

> GREL: ist alles im Row Template steht, was in den doppelten geschweiften Klammer ist `{{...}}`

> Rechts im **Templating Export** ist der Vorschau.

![Templating Export](https://sakura-72.github.io/my-bain-blog/images/templating_openrefine.png)

### Aufgabe 1: «Reverse Engineering»
Für die erste Aufgabe mussten wir die obenstehende Vorlage und die Ausgangsdaten anschauen und diese mit dem Ergebnis vergleichen, mit dem Ziel die Transformationen der Felder zu beschreiben. Diese machten wir wie üblich in Teilgruppensitzungen und notierten unsere Überlegungen im [gemeinsamen Dokument](https://pad.gwdg.de/qeGjv6aPShOSg4BMJgOjkg?both#Aufgabe-1-%E2%80%9CReverse-Engineering%E2%80%9D). Ich werde allerdings selber nicht in Details darauf eingehen.

### Aufgabe 2: Template ergänzen
Bei dieser zweiten Aufgabe mit OpenRefine haben wir in Gruppen jeweils versucht, das Template zu ergänzen. Dafür war die [Liste der MARC21 Felder der Library of Congress](https://www.loc.gov/marc/bibliographic/) sehr hilfreich und die bibliothekarische Kenntnisse innerhalb der Gruppe von grossen Vorteil. In unsere Gruppe habe wir diese Linien geschrieben, um den Row Template zu ergänzen:

```
{{
forEach(cells['Subjects'].value.split('|'), v ,'
<datafield tag="650" ind1="0" ind2=" ">
    <subfield code="a">' + v.escape('xml') + '</subfield>
</datafield>')
}}
```

Damit werden jedes behandeltes Thema jeder Publikation ausgelesen und gedruckt. Auch wird zwischen den Themen einen Strich hinzugefügt. Um dies für jede Zelle zu haben, lassten wird uns von der Vorlage inspierieren, in welche die gleiche Transformation mit Autoren gemacht.

***
Quellen: [Lehrmaterialien von Library Carpentry zu OpenRefine](https://librarycarpentry.org/lc-open-refine/), [Alex's blog](https://alexmuster.github.io/lerntageblog/2020/11/20/tag7.html), [Statistiken von OpenRefine](https://github.com/OpenRefine/OpenRefine/graphs/contributors), [OpenRefine in Wikipedia](https://en.wikipedia.org/wiki/OpenRefine), [Liste der MARC21 Felder der Library of Congress](https://www.loc.gov/marc/bibliographic/), [Skript](https://bain.felixlohmeier.de/#/05_metadaten-modellieren-und-schnittstellen-nutzen)
